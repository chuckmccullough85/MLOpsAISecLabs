{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e669cff0",
   "metadata": {},
   "source": [
    "\n",
    "# Lab 7: MLFlow Data\n",
    "\n",
    "| | |\n",
    "| --------- | --------------------------- |\n",
    "| Notebook  | 7_MLFlowData.ipynb    |\n",
    "| Builds On | none |\n",
    "| Time to complete | 30 minutes\n",
    "\n",
    "\n",
    "The mlflow.data module helps you record your model training and evaluation datasets to runs with MLflow Tracking, as well as retrieve dataset information from runs. It provides the following important interfaces:\n",
    "\n",
    "- `Dataset`: Represents a dataset used in model training or evaluation, including features, targets, predictions, and metadata such as the dataset’s name, digest (hash) schema, profile, and source. You can log this metadata to a run in MLflow Tracking using the mlflow.log_input() API. mlflow.data provides APIs for constructing Datasets from a variety of Python data objects, including Pandas DataFrames (mlflow.data.from_pandas()), NumPy arrays (mlflow.data.from_numpy()), Spark DataFrames (mlflow.data.from_spark() / mlflow.data.load_delta()), and more.\n",
    "\n",
    "- `DatasetSource`: Represents the source of a dataset. For example, this may be a directory of files stored in S3, a Delta Table, or a web URL. Each Dataset references the source from which it was derived. A Dataset’s features and targets may differ from the source if transformations and filtering were applied. You can get the DatasetSource of a dataset logged to a run in MLflow Tracking using the mlflow.data.get_source() API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c816410",
   "metadata": {},
   "source": [
    "Steps\n",
    "-------------\n",
    "\n",
    "The following example demonstrates how to use mlflow.data to log a training dataset to a run, retrieve information about the dataset from the run, and load the dataset’s source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45232052-daa0-41a4-894c-fe6471b099f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chuck_vbrk0he\\anaconda3\\Lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:150: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: dataset\n",
      "Dataset digest: 77a19fc0\n",
      "Dataset profile: {\"num_rows\": 1599, \"num_elements\": 1599}\n",
      "Dataset schema: {\"mlflow_colspec\": [{\"type\": \"string\", \"name\": \"fixed acidity;\\\"volatile acidity\\\";\\\"citric acid\\\";\\\"residual sugar\\\";\\\"chlorides\\\";\\\"free sulfur dioxide\\\";\\\"total sulfur dioxide\\\";\\\"density\\\";\\\"pH\\\";\\\"sulphates\\\";\\\"alcohol\\\";\\\"quality\\\"\", \"required\": true}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CHUCK_~1\\\\AppData\\\\Local\\\\Temp\\\\tmpammv5e0c\\\\winequality-red.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.data\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "# Construct a Pandas DataFrame using iris flower data from a web URL\n",
    "dataset_source_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "df = pd.read_csv(dataset_source_url)\n",
    "# Construct an MLflow PandasDataset from the Pandas DataFrame, and specify the web URL\n",
    "# as the source\n",
    "dataset: PandasDataset = mlflow.data.from_pandas(df, source=dataset_source_url)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log the dataset to the MLflow Run. Specify the \"training\" context to indicate that the\n",
    "    # dataset is used for model training\n",
    "    mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "# Retrieve the run, including dataset information\n",
    "run = mlflow.get_run(mlflow.last_active_run().info.run_id)\n",
    "dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "print(f\"Dataset name: {dataset_info.name}\")\n",
    "print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "print(f\"Dataset schema: {dataset_info.schema}\")\n",
    "\n",
    "# Load the dataset's source, which downloads the content from the source URL to the local\n",
    "# filesystem\n",
    "dataset_source = mlflow.data.get_source(dataset_info)\n",
    "dataset_source.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564f6e5",
   "metadata": {},
   "source": [
    "\n",
    "## Pandas\n",
    "\n",
    "Constructs a PandasDataset instance from a Pandas DataFrame, optional targets, optional predictions, and source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf52f407-46ce-4510-9856-87985802658d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.data.pandas_dataset.PandasDataset at 0x2372dc22930>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame(\n",
    "    [[\"tom\", 10, 1, 1], [\"nick\", 15, 0, 1], [\"juli\", 14, 1, 1]],\n",
    "    columns=[\"Name\", \"Age\", \"Label\", \"ModelOutput\"],\n",
    ")\n",
    "dataset = mlflow.data.from_pandas(x, targets=\"Label\", predictions=\"ModelOutput\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5ad31",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## NumPy \n",
    "\n",
    "Constructs a NumpyDataset object from NumPy features, optional targets, and source. If the source is path like, then this will construct a DatasetSource object from the source path. Otherwise, the source is assumed to be a DatasetSource object.\n",
    "\n",
    "### basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c45071-027a-432f-8056-2a074a114469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.uniform(size=[2, 5, 4])\n",
    "y = np.random.randint(2, size=[2])\n",
    "dataset = mlflow.data.from_numpy(x, targets=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8265fb",
   "metadata": {},
   "source": [
    "\n",
    "### Dict Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0dc5e8-201c-4135-a955-0bb77aeddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "x = {\n",
    "    \"feature_1\": np.random.uniform(size=[2, 5, 4]),\n",
    "    \"feature_2\": np.random.uniform(size=[2, 5, 4]),\n",
    "}\n",
    "y = np.random.randint(2, size=[2])\n",
    "dataset = mlflow.data.from_numpy(x, targets=y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
